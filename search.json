[
  {
    "objectID": "02-exploring-diabetes-data.html",
    "href": "02-exploring-diabetes-data.html",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "",
    "text": "In this session, we perform an exploratory data analysis on a simulated diabetes dataset for 2015 and 2025. The dataset used in this tutorial is simulated, this means that the 2015 and 2025 data are not real patient records and are not drawn from GBD estimates or surveillance systems. Instead, they consist of synthetic data designed to resemble realistic diabetes patterns over time, including changes in prevalence, laboratory measurements, and population structure.\nThe use of simulated data allows the analysis to focus on methodology, workflow, and interpretation, without privacy constraints or data access limitations. All results should therefore be interpreted as illustrative examples of analytical techniques rather than as epidemiological estimates.\nTo explore how diabetes prevalence and characteristics vary over time and across populations, in this tutorial we will cover:\n\nData Import\nPre-processing\nExploratory Data Visualization (EDA)\nSummary Statistics\nPrevalence Calculation\nQualitative Statistical Inference\n\n\nWhy Diabetes?\n\nDiabetes is a chronic health condition that affects how the body turns food into energy (blood glucose). It includes Type 1, Type 2, and gestational diabetes. The dataset used in this analysis contains information on individuals’ diabetes status, laboratory measurements (such as HbA1c levels), demographic information (age, sex, country), and other health-related variables.\nAt the population level, diabetes is a major contributor to illness (morbidity) and premature death (mortality). Classified as a non-communicable disease (NCD), it is associated with various complications, including cardiovascular disease, kidney failure, and neuropathy.\n\nThe Global Burden of Disease (GBD) study often identifies diabetes as a key driver of global health loss. According to GBD 2023 estimates, approximately 561 million people were living with diabetes worldwide in 2023, which is roughly \\(7\\%\\) of the world’s population (561 million out of \\(~8\\) billion).1 In the same year, diabetes accounted for about 90.2 million disability-adjusted life years (DALYs) globally, representing approximately \\(3.2\\%\\) of total global DALYs. Diabetes also contributed substantially to non-fatal health loss, with an estimated 44.2 million years lived with disability (YLDs) in 2023, representing about \\(4.5\\%\\) of all global YLDs.2\nFrom an analytical perspective, diabetes is commonly studied using measures such as prevalence rates, risk factors, and associations with other health conditions. Typical statistical tools include descriptive statistics, hypothesis testing (e.g., chi-square tests for categorical variables) for group comparisons, and exploratory methods such as clustering, regression analysis, and, in some settings, survival analysis.\n\nTo focus the analysis, we begin by defining the research questions addressed in this tutorial:\n\n\nHas the prevalence of diabetes changed significantly between 2015 and 2025?\n\n\n\n\nDoes the prevalence of diabetes differ significantly between countries in the year 2025?",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#overview",
    "href": "02-exploring-diabetes-data.html#overview",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "",
    "text": "In this session, we perform an exploratory data analysis on a simulated diabetes dataset for 2015 and 2025. The dataset used in this tutorial is simulated, this means that the 2015 and 2025 data are not real patient records and are not drawn from GBD estimates or surveillance systems. Instead, they consist of synthetic data designed to resemble realistic diabetes patterns over time, including changes in prevalence, laboratory measurements, and population structure.\nThe use of simulated data allows the analysis to focus on methodology, workflow, and interpretation, without privacy constraints or data access limitations. All results should therefore be interpreted as illustrative examples of analytical techniques rather than as epidemiological estimates.\nTo explore how diabetes prevalence and characteristics vary over time and across populations, in this tutorial we will cover:\n\nData Import\nPre-processing\nExploratory Data Visualization (EDA)\nSummary Statistics\nPrevalence Calculation\nQualitative Statistical Inference\n\n\nWhy Diabetes?\n\nDiabetes is a chronic health condition that affects how the body turns food into energy (blood glucose). It includes Type 1, Type 2, and gestational diabetes. The dataset used in this analysis contains information on individuals’ diabetes status, laboratory measurements (such as HbA1c levels), demographic information (age, sex, country), and other health-related variables.\nAt the population level, diabetes is a major contributor to illness (morbidity) and premature death (mortality). Classified as a non-communicable disease (NCD), it is associated with various complications, including cardiovascular disease, kidney failure, and neuropathy.\n\nThe Global Burden of Disease (GBD) study often identifies diabetes as a key driver of global health loss. According to GBD 2023 estimates, approximately 561 million people were living with diabetes worldwide in 2023, which is roughly \\(7\\%\\) of the world’s population (561 million out of \\(~8\\) billion).1 In the same year, diabetes accounted for about 90.2 million disability-adjusted life years (DALYs) globally, representing approximately \\(3.2\\%\\) of total global DALYs. Diabetes also contributed substantially to non-fatal health loss, with an estimated 44.2 million years lived with disability (YLDs) in 2023, representing about \\(4.5\\%\\) of all global YLDs.2\nFrom an analytical perspective, diabetes is commonly studied using measures such as prevalence rates, risk factors, and associations with other health conditions. Typical statistical tools include descriptive statistics, hypothesis testing (e.g., chi-square tests for categorical variables) for group comparisons, and exploratory methods such as clustering, regression analysis, and, in some settings, survival analysis.\n\nTo focus the analysis, we begin by defining the research questions addressed in this tutorial:\n\n\nHas the prevalence of diabetes changed significantly between 2015 and 2025?\n\n\n\n\nDoes the prevalence of diabetes differ significantly between countries in the year 2025?",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#packages",
    "href": "02-exploring-diabetes-data.html#packages",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Packages",
    "text": "Packages\nBefore we start, we load a small set of packages.\nInstall Required Packages\n\ninstall.packages(c(\"readxl\", \"janitor\", \"tidyverse\", \n                   \"scales\", \"crosstable\", \n                   \"vcd\", \"DescTools\",\n                   \"cluster\",\"clustMixType\"))\n\nLoad Required Libraries\n\n# Packages for Data Manipulation and Visualization\nlibrary(readxl) # For read_excel()\nlibrary(janitor) # For clean_names()\nlibrary(tidyverse) # For data manipulation and visualization\n# tidyverse::tidyverse_packages()\nlibrary(scales) # For scale_y_continuous(labels = scales::percent)\nlibrary(crosstable) # For crosstable()\n# Packages for Clustering\nlibrary(vcd)    # For assocstats()\nlibrary(DescTools) # For CramerV()\nlibrary(cluster) # For data manipulation\nlibrary(clustMixType) # For k-prototypes clustering",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#data-import",
    "href": "02-exploring-diabetes-data.html#data-import",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Data Import",
    "text": "Data Import\nData are stored in one Excel file with two sheets: one for 2015 and one for 2025. We read each sheet into R and clean the column names so they are consistent and easy to type.\nWe use the read_excel function from the readxl package to read the data and the clean_names function from the janitor package to clean the column names.\n\npath &lt;- \"data/diabetes_study_filled_NEW.xlsx\"\n\nd2015 &lt;- readxl::read_excel(path, \n                            sheet = \"2015\") \nd2025 &lt;- readxl::read_excel(path, \n                            sheet = \"2025\")",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#pre-processing",
    "href": "02-exploring-diabetes-data.html#pre-processing",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Pre-processing",
    "text": "Pre-processing\nThe pre-processing phase is crucial for ensuring the quality and integrity of the data before conducting any analysis. Data are often messy and may contain inconsistencies, missing values, or irrelevant information that can affect the results of the analysis.\nData Manipulation\nCombine data for comparative analyses by year is straightforward, we stack the two datasets into a single table and add a year column. This is data manipulation; we merge the two datasets from 2015 and 2025 into a single dataset, adding a new column to indicate the year of each observation.\nIn particular, we use the bind_rows function from the dplyr package to stack the two datasets vertically, and the mutate function to create a new column called year.\n\ndata_raw &lt;- bind_rows(\n  d2015 %&gt;% mutate(year = 2015),\n  d2025 %&gt;% mutate(year = 2025)) %&gt;% \n  janitor::clean_names()\n\nData Inspection\nThe first step is to check the initial structure of the data and identify any missing values. We can use the head function to view the first few rows of the dataset.\n\n# Checking initial structure\nhead(data_raw)\n\n# A tibble: 6 × 9\n   year country   age sex   bmi_cat       sdi     lab_hba1c diabetes_self_report\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;               \n1  2015 Brazil     42 woman Obesity       Interm…       4.9 no                  \n2  2015 Brazil     64 woman Normal weight Interm…       6.1 no                  \n3  2015 Brazil     82 woman Obesity       Interm…       4.8 no                  \n4  2015 Brazil     55 woman Normal weight Interm…       6   no                  \n5  2015 Brazil     59 woman Underweight   Interm…       5.6 no                  \n6  2015 Brazil     42 men   Normal weight Interm…       6.3 no                  \n# ℹ 1 more variable: gestational_diabetes &lt;chr&gt;\n\n\nThen, we perform data inspection with the str or glimpse functions to understand the data types and structure of each variable. Both functions provide a concise summary of the dataset, including the number of observations, variables, and their respective data types.\n\nglimpse(data_raw)\n\nRows: 500\nColumns: 9\n$ year                 &lt;dbl&gt; 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2015, 2…\n$ country              &lt;chr&gt; \"Brazil\", \"Brazil\", \"Brazil\", \"Brazil\", \"Brazil\",…\n$ age                  &lt;dbl&gt; 42, 64, 82, 55, 59, 42, 54, 51, 73, 66, 54, 65, 4…\n$ sex                  &lt;chr&gt; \"woman\", \"woman\", \"woman\", \"woman\", \"woman\", \"men…\n$ bmi_cat              &lt;chr&gt; \"Obesity\", \"Normal weight\", \"Obesity\", \"Normal we…\n$ sdi                  &lt;chr&gt; \"Intermediate\", \"Intermediate\", \"Intermediate\", \"…\n$ lab_hba1c            &lt;dbl&gt; 4.9, 6.1, 4.8, 6.0, 5.6, 6.3, 5.2, 5.8, 6.2, 6.0,…\n$ diabetes_self_report &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n$ gestational_diabetes &lt;chr&gt; \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"no\", \"…\n\n\nHandling Missing Values\nNext, we check for missing values (NA) with is.na function. This function returns a logical matrix indicating the presence of missing values in the dataset. To count the number of missing values in each column, we can use the colSums function in combination with is.na.\n\n# Checking missing values (NA)\ncolSums(is.na(data_raw))\n\n                year              country                  age \n                   0                    0                    0 \n                 sex              bmi_cat                  sdi \n                   0                    0                    0 \n           lab_hba1c diabetes_self_report gestational_diabetes \n                   0                    0                    0 \n\n\nThere aren’t missing values in the dataset, but if there were, we could handle them using various strategies such as imputation, removal, or flagging, depending on the nature and extent of the missing data.\n\n\n\n\n\n\nNoteQuestion\n\n\n\nHow would you handle missing values in a dataset? What strategies would you consider?\n\n\nCreating Derived Variables\nData are usually not in the exact format needed for analysis. Therefore, we create new variables based on existing ones to facilitate the analysis. We are looking at making comparisons between two years to see how diabetes level changes along the time.\nIn this case, we create three derived variables:\n\nLaboratory-defined diabetes (\\(HbA1c ≥ 6.5\\))\nTotal diabetes (self-report OR laboratory, excluding gestational diabetes)\nAge groups (set of age bands to support grouped summaries)\n\nThis step involves using the mutate function from the dplyr package to create new columns based on conditions applied to existing columns. And we use the if_else and case_when functions to define the logic for these new variables.\n\ndf_diabetes &lt;- data_raw %&gt;%\n  mutate(\n    # Laboratory-defined diabetes\n    diabetes_lab = if_else(lab_hba1c &gt;= 6.5, \n                           \"yes\", \"no\", \n                           missing = NA_character_),\n    # Total diabetes (self-report OR laboratory, excluding gestational diabetes)\n    diabetes_total = case_when(\n      gestational_diabetes == \"yes\" ~ \"no\",\n      diabetes_self_report == \"yes\" | diabetes_lab == \"yes\" ~ \"yes\",\n      TRUE ~ \"no\"),\n    # Age groups\n    age_group = case_when(\n      age &lt; 50 ~ \"40–49\",\n      age &lt; 60 ~ \"50–59\",\n      TRUE ~ \"60+\")\n    )",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#exploratory-data-analysis-eda",
    "href": "02-exploring-diabetes-data.html#exploratory-data-analysis-eda",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Exploratory data Analysis (EDA)",
    "text": "Exploratory data Analysis (EDA)\nExploratory Data Analysis (EDA) is a crucial step in understanding the underlying patterns, relationships, and distributions within a dataset. It involves using various statistical and graphical techniques to summarize and visualize the data. EDA helps to identify potential issues, outliers, and trends that may inform subsequent analyses or modelling efforts.\nDistribution plot for HbA1c (2015 only)\nLet’s visualize the distribution of HbA1c levels for the year 2015 using a histogram combined with a density plot. This will help us understand the spread and central tendency of HbA1c values in that year.\n\nggplot(data = d2015, \n       aes(x = lab_hba1c)) +\n  geom_histogram(aes(y = after_stat(density)), \n                 bins = 30,\n                 fill = \"lightblue\", \n                 color = \"grey70\") +\n  geom_density(color = \"darkblue\", \n               linewidth = 1) +\n  labs(title = \"HbA1c Distribution (2015)\",\n       x = \"HbA1c (%)\",\n       y = \"Density\") \n\n\n\n\n\n\n\nWe can see that the distribution of HbA1c levels in 2015 is right-skewed, with a peak around \\(5-6\\%\\). This indicates that most individuals had HbA1c levels within the normal range, but there is a tail of higher values indicating some individuals with elevated HbA1c levels.\nHbA1c distribution in both years\nTo compare the distribution of HbA1c levels between 2015 and 2025, we can create a density plot that overlays the distributions for both years. This will allow us to visually assess any changes in HbA1c levels over time.\n\ndf_diabetes %&gt;%\n  ggplot(aes(x = lab_hba1c, \n           fill = as.factor(year))) +\n  geom_density(alpha = 0.5,\n               linewidth = 0.2) +\n  labs(title = \"HbA1c Distribution — 2015 vs 2025\",\n       x = \"HbA1c (%)\",\n       y = \"Density\",\n       fill = \"Year\")\n\n\n\n\n\n\n\nAge distribution by year\nTo check the age distribution for both years, we can create overlapping histograms. This will help us visualize how the age distribution of the population has changed from 2015 to 2025.\n\nggplot(data = df_diabetes,\n       mapping = aes(x = age, \n                     fill = factor(year))) +\n  geom_histogram(position = \"identity\", \n                 color = \"grey80\",\n                 alpha = 0.5, bins = 30) +\n  labs(title = \"Age Distribution: 2015 vs 2025\",\n       fill = \"Year\",\n       x = \"Age\",\n       y = \"Count\")\n\n\n\n\n\n\n\nAge Boxplots\nTo further explore the age distribution by year and gender (sex), we can create boxplots. Boxplots provide a visual summary of the distribution, median, quartiles, and potential outliers for age across different years and genders.\n\nggplot(df_diabetes,\n       aes(x = factor(year), y = age, \n           fill = factor(year))) +\n  geom_boxplot(median.color = \"grey70\",) +\n  scale_fill_manual(values = c(\"2015\" = \"lightblue\", \n                             \"2025\" = \"salmon\")) +\n  facet_wrap(~sex) +\n  labs(title = \"Age Distribution by Year\",\n       x = \"Year\",\n       y = \"Age\",\n       fill = \"Year\") \n\n\n\n\n\n\n\nThis plot shows the age distribution for both years separately for males and females. We can observe any shifts in median age or variability between the two years and across genders. We do not have outliers in this dataset.",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#summary-statistics",
    "href": "02-exploring-diabetes-data.html#summary-statistics",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nNow that we have explored the data visually, we can compute some summary statistics to quantify key characteristics of the dataset, and compare them across the two years.\n\ndf_diabetes %&gt;%\n  summarise(\n    n = n(),\n    age_mean = mean(age, na.rm = TRUE),\n    age_sd   = sd(age, na.rm = TRUE),\n    hba1c_mean = mean(lab_hba1c, na.rm = TRUE),\n    hba1c_sd   = sd(lab_hba1c, na.rm = TRUE)\n    ) %&gt;%\n  round(2) %&gt;% # Round to 2 decimal places\n  t() # Transpose for better layout\n\n             [,1]\nn          500.00\nage_mean    56.34\nage_sd      11.86\nhba1c_mean   5.96\nhba1c_sd     0.92\n\n\nThe results show the overall mean and standard deviation for age and HbA1c levels across the entire dataset, without stratifying by year.\nThe mean age is approximately 56 years, with a standard deviation of about 12 years, indicating a middle-aged population with some variability in age. The mean HbA1c level is around \\(6.2\\%\\), with a standard deviation of about \\(1.5\\%\\), suggesting that, on average, the population has HbA1c levels slightly above the normal range (typically \\(&lt;5.7\\%\\) for non-diabetic individuals), with considerable variability.\nComparisons by Year\nTo compare these statistics by year, we can use the group_by function to group the data by the year variable before summarising.\n\ndf_diabetes %&gt;%\n  group_by(year) %&gt;%\n  summarise(\n    n = n(),\n    age_mean = mean(age, na.rm = TRUE),\n    hba1c_mean = mean(lab_hba1c, na.rm = TRUE)\n    )\n\n# A tibble: 2 × 4\n   year     n age_mean hba1c_mean\n  &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt;      &lt;dbl&gt;\n1  2015   250     56.7       5.87\n2  2025   250     56.0       6.05",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#prevalence-calculation",
    "href": "02-exploring-diabetes-data.html#prevalence-calculation",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Prevalence Calculation",
    "text": "Prevalence Calculation\nTo calculate the prevalence of diabetes for each year, we can use the group_by and summarise functions to compute the mean of the binary indicator for diabetes status.\n\nprev_diabetes &lt;- df_diabetes %&gt;%\n  group_by(year, diabetes_total) %&gt;%\n  summarise(n = n(), .groups = \"drop\") %&gt;%\n  group_by(year) %&gt;% \n  mutate(prop = n / sum(n))\n\nprev_diabetes\n\n# A tibble: 4 × 4\n# Groups:   year [2]\n   year diabetes_total     n  prop\n  &lt;dbl&gt; &lt;chr&gt;          &lt;int&gt; &lt;dbl&gt;\n1  2015 no               212 0.848\n2  2015 yes               38 0.152\n3  2025 no               188 0.752\n4  2025 yes               62 0.248\n\n\n\nprev_summary &lt;- df_diabetes %&gt;%\n  group_by(year) %&gt;%\n  summarise(prev_diabetes = mean(diabetes_total == \"yes\", \n                                 na.rm=TRUE))\nprev_summary\n\n# A tibble: 2 × 2\n   year prev_diabetes\n  &lt;dbl&gt;         &lt;dbl&gt;\n1  2015         0.152\n2  2025         0.248\n\n\nPrevalence Table with Confidence Intervals\nTo calculate prevalence with confidence intervals, we can use the prop.test function within a custom summarise operation.\n\nprev_ci &lt;- df_diabetes %&gt;%\n  group_by(year) %&gt;%\n  summarise(\n    n = n(),\n    cases = sum(diabetes_total == \"yes\", na.rm = TRUE),\n    prev = cases / n,\n    ci_lower = prop.test(cases, n)$conf.int[1],\n    ci_upper = prop.test(cases, n)$conf.int[2]\n  )\nprev_ci\n\n# A tibble: 2 × 6\n   year     n cases  prev ci_lower ci_upper\n  &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1  2015   250    38 0.152    0.111    0.204\n2  2025   250    62 0.248    0.197    0.307\n\n\nVisualize diabetes prevalence by year\nTo visualize diabetes prevalence by year, we can create a bar plot with the errorbars representing the confidence intervals. This plot will show the proportion of individuals with diabetes for each year.\n\nggplot(prev_ci, \n       aes(x = factor(year), \n           y = prev, \n           fill = factor(year))) +\n  geom_col() +\n  geom_errorbar(aes(ymin = ci_lower, \n                    ymax = ci_upper), \n                width = 0.2) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_manual(values = c(\"2015\" = \"lightblue\", \n                               \"2025\" = \"salmon\")) +\n  labs(title = \"Diabetes Prevalence by Year\",\n       x = \"Year\",\n       y = \"Prevalence (%)\",\n       fill = \"Year\")\n\n\n\n\n\n\n\nThis barplot shows the prevalence of diabetes for each year, along with the 95% confidence intervals. We can visually assess any changes in prevalence between 2015 and 2025.\nInteraction\nTo explore the interaction between gender, age, and diabetes status, we can create a faceted bar plot. This plot will show the distribution of diabetes status across different age groups, separated by gender.\n\nggplot(df_diabetes, \n       aes(x = age_group, \n           fill = diabetes_total)) +\n  geom_bar(position = \"fill\",\n           color = \"white\",\n           linewidth = 2) +\n  scale_y_continuous(labels = scales::percent) +\n  scale_fill_manual(values = c(\"yes\" = \"lightblue\", \n                               \"no\" = \"salmon\")) +\n  labs(title = \"Diabetes Status by Age Group and Gender\",\n       x = \"Age Group\",\n       y = \"Proportion\",\n       fill = \"Diabetes Status\") +\n  facet_wrap(~sex)\n\n\n\n\n\n\n\nInteraction between gender, age and diabetes\n\nggplot(df_diabetes, \n       aes(x = diabetes_total, y = age, \n           fill = sex)) +\n  geom_boxplot(median.color = \"gray40\",\n               outlier.color = \"gray40\") +\n  scale_fill_manual(values = c(\"men\" = \"lightblue\",\n                               \"woman\" = \"salmon\")) +\n  labs(title = \"Age Distribution by Diabetes Status and Gender\",\n       x = \"Diabetes\",\n       y = \"Age\",\n       fill = \"Gender\") \n\n\n\n\n\n\n\nHere, we can observe how the proportion of individuals with diabetes varies across age groups for both men and women. Additionally, the boxplot shows the age distribution for individuals with and without diabetes, separated by gender.",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#qualitative-statistical-inference",
    "href": "02-exploring-diabetes-data.html#qualitative-statistical-inference",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Qualitative Statistical Inference",
    "text": "Qualitative Statistical Inference\nTo answer our research questions regarding diabetes prevalence, we will use the Chi-Square Test of Independence. This test is appropriate for categorical data and helps us determine whether there is a significant association between two categorical variables.\n\nQuestion 1: The prevalence of diabetes changed significantly between 2015 and 2025?\n\nChi-square Test for Year and Diabetes Status\n\ntable_year &lt;- table(df_diabetes$year, \n                    df_diabetes$diabetes_total)\n\ntable_year\n\n      \n        no yes\n  2015 212  38\n  2025 188  62\n\n\n\nchi_year &lt;- chisq.test(table_year)\n\nchi_year\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table_year\nX-squared = 6.6125, df = 1, p-value = 0.01013\n\n\nThe p-value is below 0.05, so we reject the null hypothesis and conclude that prevalence differs between 2015 and 2025 in this dataset.\n\nchi_year$expected\n\n      \n        no yes\n  2015 200  50\n  2025 200  50\n\n\n\n# Standardized Residuals\nres_year &lt;- chi_year$stdres\nres_year\n\n      \n              no       yes\n  2015  2.683282 -2.683282\n  2025 -2.683282  2.683282\n\n\n\nQuestion 2: Will the prevalence of diabetes differ significantly between countries in the year 2025?\n\nChi-square Test for Country and Diabetes Status in 2025\n\ndf_diabetes_2025 &lt;- df_diabetes %&gt;% filter(year == 2025)\n\nContingency table for countries and diabetes\n\ntab_2025 &lt;- table(df_diabetes_2025$country,\n                  df_diabetes_2025$diabetes_total)\ntab_2025\n\n              \n               no yes\n  Brazil       42  25\n  China        39  11\n  Italy        40  10\n  South Africa 27   6\n  USA          40  10\n\n\n\nchi_2025 &lt;- chisq.test(tab_2025)\nchi_2025\n\n\n    Pearson's Chi-squared test\n\ndata:  tab_2025\nX-squared = 7.8461, df = 4, p-value = 0.09738\n\n\nThe p-value is greater than 0.05. Therefore, we fail to reject the null hypothesis and conclude that there is no statistically significant difference in diabetes prevalence between countries in 2025.\n\nchi_2025$expected\n\n              \n                   no    yes\n  Brazil       50.384 16.616\n  China        37.600 12.400\n  Italy        37.600 12.400\n  South Africa 24.816  8.184\n  USA          37.600 12.400\n\n\n\n# Standardized Residuals\nresiduals &lt;- chi_2025$stdres\nround(residuals, 2)\n\n              \n                  no   yes\n  Brazil       -2.77  2.77\n  China         0.51 -0.51\n  Italy         0.88 -0.88\n  South Africa  0.94 -0.94\n  USA           0.88 -0.88\n\n\nIdentify where the greatest contribution lies:\n\nmosaicplot(tab_2025,\n           main = \"Mosaic Plot — Diabetes by Country (2025)\",\n           color = TRUE, las = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoteInterpretation\n\n\n\nInterpretation: We fail to reject the null hypothesis. There is no statistically significant evidence that diabetes prevalence differs between countries in 2025 at the 5% significance level.\nAlthough some countries show larger deviations from expected counts, these differences are not strong enough, overall, to conclude that prevalence differs significantly across countries.",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#k-prototypes-clustering",
    "href": "02-exploring-diabetes-data.html#k-prototypes-clustering",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "K-prototypes Clustering",
    "text": "K-prototypes Clustering\nIn this final analytical step, we explore whether individuals in the 2025 dataset can be grouped into distinct profiles based on a combination of clinical and demographic characteristics. Rather than focusing on hypothesis testing, this section introduces unsupervised learning as an exploratory tool to uncover structure in the data.\nClustering is particularly useful in public health settings when the goal is to:\n- identify subgroups with similar risk profiles,\n- explore heterogeneity within a population,\n- generate hypotheses for targeted interventions.\nBecause our dataset contains both numeric and categorical variables, we use the k-prototypes algorithm, which is specifically designed for mixed-type data.\n\nWhy k-prototypes?\n\nTraditional clustering methods such as k-means only work with numeric variables, while k-modes are limited to categorical data. The k-prototypes algorithm combines both approaches:\n- Euclidean distance is used for numeric variables,\n- matching dissimilarity is used for categorical variables,\n- a tuning parameter ($\\lambda$) balances the contribution of each type.\nThis makes k-prototypes well suited for health datasets that mix laboratory values (e.g. HbA1c) with demographic or clinical categories (e.g. sex, BMI group, age band).\nData Preparation for Clustering\nWe restrict the clustering analysis to observations from 2025, as the aim is to characterise the most recent population snapshot rather than temporal change.\n\nstr(df_diabetes_2025)\n\ntibble [250 × 12] (S3: tbl_df/tbl/data.frame)\n $ year                : num [1:250] 2025 2025 2025 2025 2025 ...\n $ country             : chr [1:250] \"Brazil\" \"Brazil\" \"Brazil\" \"Brazil\" ...\n $ age                 : num [1:250] 44 83 45 48 48 47 55 66 57 66 ...\n $ sex                 : chr [1:250] \"woman\" \"men\" \"woman\" \"men\" ...\n $ bmi_cat             : chr [1:250] \"Normal weight\" \"Overweight\" \"Obesity\" \"Normal weight\" ...\n $ sdi                 : chr [1:250] \"Intermediate\" \"Intermediate\" \"Intermediate\" \"Intermediate\" ...\n $ lab_hba1c           : num [1:250] 6 6.1 5.8 5.9 5.3 6.3 8.8 5.4 5.3 6.4 ...\n $ diabetes_self_report: chr [1:250] \"no\" \"no\" \"no\" \"yes\" ...\n $ gestational_diabetes: chr [1:250] \"no\" \"no\" \"no\" \"no\" ...\n $ diabetes_lab        : chr [1:250] \"no\" \"no\" \"no\" \"no\" ...\n $ diabetes_total      : chr [1:250] \"no\" \"no\" \"no\" \"yes\" ...\n $ age_group           : chr [1:250] \"40–49\" \"60+\" \"40–49\" \"40–49\" ...\n\n\nBefore clustering, variables must be correctly typed. Numeric variables should remain numeric, while categorical variables must be encoded as factors.\n\ncluster_data_2025 &lt;- df_diabetes_2025 %&gt;%\n  select(-year)%&gt;%\n  mutate(across(where(is.character), as.factor))\n\nstr(cluster_data_2025)\n\ntibble [250 × 11] (S3: tbl_df/tbl/data.frame)\n $ country             : Factor w/ 5 levels \"Brazil\",\"China\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ age                 : num [1:250] 44 83 45 48 48 47 55 66 57 66 ...\n $ sex                 : Factor w/ 2 levels \"men\",\"woman\": 2 1 2 1 1 2 2 1 1 2 ...\n $ bmi_cat             : Factor w/ 4 levels \"Normal weight\",..: 1 3 2 1 2 2 2 3 2 2 ...\n $ sdi                 : Factor w/ 3 levels \"High\",\"Intermediate\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ lab_hba1c           : num [1:250] 6 6.1 5.8 5.9 5.3 6.3 8.8 5.4 5.3 6.4 ...\n $ diabetes_self_report: Factor w/ 2 levels \"no\",\"yes\": 1 1 1 2 1 2 1 1 1 2 ...\n $ gestational_diabetes: Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ diabetes_lab        : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 1 1 1 2 1 1 1 ...\n $ diabetes_total      : Factor w/ 2 levels \"no\",\"yes\": 1 1 1 2 1 2 2 1 1 2 ...\n $ age_group           : Factor w/ 3 levels \"40–49\",\"50–59\",..: 1 3 1 1 1 1 2 3 2 3 ...\n\n\nAt this stage, the dataset contains a mixture of numeric and categorical features suitable for k-prototypes clustering.\nChecking Redundancy and Association Between Variables\nClustering can be distorted if highly redundant variables are included. We therefore assess association within numeric variables and dependence among categorical variables.\nNumeric Correlation (Pearson)\n\ncluster_data_2025 %&gt;%\n  select_if(is.numeric) %&gt;%\n  cor()\n\n                  age   lab_hba1c\nage       1.000000000 0.008397291\nlab_hba1c 0.008397291 1.000000000\n\n\nAge and HbA1c show little correlation, so both can be retained. However, age_group is derived directly from age, so age is removed later to avoid duplicating the same information. So we will drop age from the clustering dataset.\n\nfeatures_num &lt;- c(#\"age\", \n                  \"lab_hba1c\")\n\nCategorical Association (Cramér’s V)\nFor categorical variables, we use Cramér’s V, a normalized measure derived from the chi-square statistic:\n\\[\nV = \\sqrt{\\frac{\\chi^2 / n}{\\min(k - 1, r - 1)}}\n\\tag{1}\\]\nWhere:\n- (\\(\\chi^2\\)) is the Chi-square statistic\n- (\\(n\\)) is the total number of observations\n- (\\(k\\)) is the number of categories in one variable\n- (\\(r\\)) is the number of categories in the other variable\nCramer V is a measure of association between two nominal categorical variables. It ranges from 0 (no association) to 1 (perfect association). It is based on the Chi-square statistic and is useful for understanding the strength of association between categorical variables.\nThe inventor of Cramér’s V, Harald Cramér, did not specify strict cut-offs for interpreting the values. However, in practice, researchers often use the following guidelines to interpret the strength of association:\n\n0 to 0.1: Negligible association\n0.1 to 0.3: Weak association\n0.3 to 0.5: Moderate association\n0.5 to 1.0: Strong association\n\nIn this case, we will identify pairs of categorical variables with Cramér’s V less than or equal to 0.5, indicating weak to moderate associations.\nWe first examine the relationship between country and sdi, which are conceptually related using the assocstats() function from the vcd package:\n\nvcd::assocstats(table(cluster_data_2025$country, cluster_data_2025$sdi))$cramer\n\n[1] 0.8998341\n\n\nOr, we can even use the CramerV() function from the DescTools package:\n\nDescTools::CramerV(cluster_data_2025$country, cluster_data_2025$sdi)\n\n[1] 0.8998341\n\n\nBoth packages show a value of 0.9, indicating a high association between country and SDI. The high association suggests that including both variables may overweight the same socioeconomic information. However, association with other categorical variables is weaker, so this decision is not automatic and requires judgement.\nTest all pairs of categorical features\nTo examine this systematically, we compute Cramér’s V for all pairs of categorical variables setting up a function to compute Cramér’s V for any two categorical variables:\n\ncramers_v &lt;- function(x, y) CramerV(table(x, y))\n\nExtract the names of all categorical features:\n\ncluster_data_2025 %&gt;%\n  select(where(is.factor)) %&gt;%\n  names()\n\n[1] \"country\"              \"sex\"                  \"bmi_cat\"             \n[4] \"sdi\"                  \"diabetes_self_report\" \"gestational_diabetes\"\n[7] \"diabetes_lab\"         \"diabetes_total\"       \"age_group\"           \n\n\nWe focus on a subset of categorical features for clarity:\n\nfeatures_cat &lt;- c(\"sex\", \n                  \"bmi_cat\", \n                  #\"country\", \n                  #\"sdi\",\n                  \"age_group\")\n\nThen we use the expand_grid function to create all possible pairs of categorical features, compute Cramér’s V for each pair, and filter for weak to moderate associations (Cramér’s V &lt;= 0.5):\n\nexpand_grid(feature1 = features_cat,\n            feature2 = features_cat) %&gt;%\n  filter(feature1 &lt; feature2) %&gt;% # keep unique pairs only\n  rowwise() %&gt;%\n  mutate(cramers_v = cramers_v(\n    cluster_data_2025[[feature1]],\n    cluster_data_2025[[feature2]])) %&gt;%\n  # Filter for Cramér's V &lt;= 0.5 to identify weak to moderate associations\n  filter(cramers_v &lt;= 0.5) %&gt;%\n  arrange(desc(cramers_v)) -&gt; cramers_df\n\ncramers_df\n\n# A tibble: 3 × 3\n# Rowwise: \n  feature1  feature2 cramers_v\n  &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt;\n1 bmi_cat   sex         0.124 \n2 age_group sex         0.0698\n3 age_group bmi_cat     0.0578\n\n\nThis confirms that the retained categorical variables are not strongly redundant.\nData Quality Checks: Outliers and Rare Categories\nBefore clustering, we check:\n- outliers in numeric variables,\n- imbalanced categories in categorical variables.\n\ncluster_data_2025 %&gt;%\n  select(lab_hba1c) %&gt;%\n  ggplot() +\n  geom_boxplot(aes(x = lab_hba1c)) \n\n\n\n\n\n\n\nWe can see the presence of outliers in lab_hba1c variable. To handle these outliers , we can perform a technique called winsorization, which involves capping extreme values to reduce their impact on the analysis. In this case, we will cap the values at the 1st and 99th percentiles.\nThe extreme values in lab_hba1c can disproportionately influence the clustering results.\n\nsummary(cluster_data_2025$lab_hba1c)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  4.800   5.400   5.800   6.052   6.300   8.900 \n\n\nThe maximum value of lab_hba1c before winsorization is 8.9.\nThen we calculate the upper whisker value using the interquartile range (IQR) method.\n\nQ1 &lt;- quantile(cluster_data_2025$lab_hba1c, 0.25)\nQ3 &lt;- quantile(cluster_data_2025$lab_hba1c, 0.75)\nIQR_val &lt;- Q3 - Q1\nupper_whisker &lt;- Q3 + 1.5 * IQR_val\n\nIn summary, winsorizing the lab_hba1c variable helps to mitigate the influence of extreme outliers on the clustering results.\nWinsorization of lab_hba1c\n\n# Save the original values\ncluster_data_2025$lab_hba1c_original &lt;- cluster_data_2025$lab_hba1c\n\nWe use pmin() function to force the lab_hba1c outliers to equal the upper whisker value, it selects the minimum out of: the existing lab_hba1c value and the upper whisker value.\n\ncluster_data_2025$lab_hba1c &lt;- pmin(cluster_data_2025$lab_hba1c, upper_whisker)\n\nAfter winsorization - where did the outliers go?\n\nboxplot(cluster_data_2025$lab_hba1c, \n        main = \"lab_hba1c – After Winsorization\",\n        horizontal = TRUE)\n\n\n\n\n\n\n\nUnbalanced categorical features\nWe check the distribution of categories in each categorical variable to ensure there are no extremely rare categories that could distort clustering.\n\ncat_balance &lt;- cluster_data_2025 %&gt;%\n  select_if(is.factor) %&gt;%\n  pivot_longer(cols = everything(),\n               names_to = \"variable\",\n               values_to = \"category\") %&gt;%\n  count(variable, category, name = \"n\") %&gt;%\n  group_by(variable) %&gt;%\n  mutate(pct = round(100 * n / sum(n), 1),\n         is_rare = (n / sum(n)) &lt; 0.05 ) %&gt;%\n  ungroup() %&gt;%\n  arrange(variable, desc(n))\n\ncat_balance\n\n# A tibble: 25 × 5\n   variable  category          n   pct is_rare\n   &lt;chr&gt;     &lt;fct&gt;         &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt;  \n 1 age_group 40–49            88  35.2 FALSE  \n 2 age_group 50–59            87  34.8 FALSE  \n 3 age_group 60+              75  30   FALSE  \n 4 bmi_cat   Normal weight   102  40.8 FALSE  \n 5 bmi_cat   Overweight       78  31.2 FALSE  \n 6 bmi_cat   Obesity          46  18.4 FALSE  \n 7 bmi_cat   Underweight      24   9.6 FALSE  \n 8 country   Brazil           67  26.8 FALSE  \n 9 country   China            50  20   FALSE  \n10 country   Italy            50  20   FALSE  \n# ℹ 15 more rows\n\n\nNo categories are extremely rare (i.e., less than 5% of total), so we can retain all categorical variables for clustering.\nScaling Numeric Variables and Final Variable Selection\nWhy scaling? Scaling numeric variables ensures that they contribute equally to the distance calculations used in clustering. Without scaling, variables with larger ranges can dominate the distance metric, leading to biased clustering results.\nWe then retain the final set of variables for clustering and standardise the numeric input.\n\ncluster_data_2025 &lt;- cluster_data_2025 %&gt;%\n  select(lab_hba1c,\n         sex,\n         age_group,\n         bmi_cat) %&gt;%\n  # here is where scaling happens\n  mutate(lab_hba1c = as.numeric(scale(lab_hba1c)))\n\nChoosing the Number of Clusters\nWe use the elbow method, examining how within-cluster variation decreases as the number of clusters increases. What we do here is run the k-prototypes algorithm for a range of cluster numbers (k = 2 to 10) and record the total within-cluster sum of squares (WSS) for each k. We use the map_dbl function from the purrr package to map over the range of k values and store the WSS results. And the kproto function from the clustMixType package to perform k-prototypes clustering on the prepared dataset for 2025.\n\nset.seed(123)\nkproto_wss_2025 &lt;- purrr::map_dbl(2:10, function(k) {\n  \n  kpres &lt;- kproto(cluster_data_2025,\n                  k, \n                  verbose = FALSE) \n    \n  kpres$tot.withinss\n})\n\nAnd plot the WSS values to identify the “elbow” point where adding more clusters yields diminishing returns in reducing WSS.\n\nplot(2:10, kproto_wss_2025, type = \"b\",\n     xlab = \"Number of clusters (k)\",\n     ylab = \"Total within-cluster sum of squares\",\n     main = \"Elbow Method (2025)\")\n\n\n\n\n\n\n\nBased on the elbow plot, we choose k = 5 as the optimal number of clusters.\n\noptimal_k &lt;- 5  # chosen from elbow\n\nRun K-prototypes Clustering\nWe use the kproto function again, but this time specifying the optimal number of clusters (k = 5) determined from the elbow method. We set a random seed for reproducibility, and configure the algorithm to run with 25 random starts and a maximum of 25 iterations per start to ensure convergence.\n\nset.seed(123456789)\nkp_model &lt;- kproto(cluster_data_2025, \n                   k = optimal_k,\n                   nstart = 25,\n                   iter.max = 25,\n                   lambda = NULL,\n                   verbose = FALSE)\n\nAdd a cluster number (1 to 5) to each datapoint in the dataset:\n\ncluster_data_2025$cluster &lt;- kp_model$cluster\n\nInterpreting the Clusters\nKey diagnostic outputs help assess clustering quality and interpretability:\n\nkp_model$size # Number of points in each cluster\n\nclusters\n 1  2  3  4  5 \n48 50 58 42 52 \n\n\nLambda balances numerical (Euclidean) vs categorical (matching) distance:\n\\[\n\\lambda =\\sum{\\frac{\\text{(std_dev of numerical features)}}{\\text{(n. numerical features)}}}\n\\tag{2}\\]\nCalculate lambda manually to verify:\n\nkp_model$lambda # Lambda value used\n\n[1] 1.614542\n\n\nThe withinss values tell us how compact each cluster is. Lower is better, it means the patients in that cluster are more similar to each other.\n\nkp_model$withinss\n\n[1]  72.60207  58.85312  94.89224 110.92214  85.94492\n\n\n\n# Compare cluster compactness\nbarplot(kp_model$withinss, \n        names.arg = paste(\"Cluster\", 1:5),\n        ylab = \"Within-cluster SS\",\n        main = \"Cluster Compactness (lower = more compact)\")\n\n\n\n\n\n\n\nThe total within-cluster sum of squares represents the overall compactness. When we did the elbow plot, we were looking at how this total changes as we add more clusters. We want tight clusters without over-fragmenting our data.\n\nkp_model$tot.withinss\n\n[1] 423.2145\n\n\nThe cluster centres for categorical variables represent modal categories, while numeric centres reflect mean values.\n\nkp_model$centers\n\n    lab_hba1c   sex age_group       bmi_cat\n1 -0.71955321   men     50–59    Overweight\n2 -0.28653701 woman     50–59 Normal weight\n3 -0.51599890   men       60+ Normal weight\n4  1.84526774   men     40–49 Normal weight\n5  0.02484799 woman     40–49    Overweight\n\n\n\ncluster_data_2025 %&gt;%\n  group_by(cluster) %&gt;%\n  summarise(\n    n = n(),\n    hba1c = round(mean(lab_hba1c), 1),\n    sex = names(which.max(table(sex))),\n    bmi_cat = names(which.max(table(bmi_cat))),\n    age = names(which.max(table(age_group)))\n  )\n\n# A tibble: 5 × 6\n  cluster     n hba1c sex   bmi_cat       age  \n    &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt;\n1       1    48  -0.7 men   Overweight    50–59\n2       2    50  -0.3 woman Normal weight 50–59\n3       3    58  -0.5 men   Normal weight 60+  \n4       4    42   1.8 men   Normal weight 40–49\n5       5    52   0   woman Overweight    40–49\n\n\nExternal Validation Using Diabetes Status\nAlthough clustering is unsupervised, we can validate the result externally by checking whether clusters align with known diabetes status.\nAdd diabetes status back to cluster data:\n\ncluster_data_2025$diabetes &lt;- df_diabetes_2025$diabetes_total\n\n\nchisq.test(table(cluster_data_2025$cluster, cluster_data_2025$diabetes))\n\n\n    Pearson's Chi-squared test\n\ndata:  table(cluster_data_2025$cluster, cluster_data_2025$diabetes)\nX-squared = 138.5, df = 4, p-value &lt; 2.2e-16\n\n\n\nassocstats(table(cluster_data_2025$cluster, cluster_data_2025$diabetes))\n\n                    X^2 df P(&gt; X^2)\nLikelihood Ratio 130.89  4        0\nPearson          138.50  4        0\n\nPhi-Coefficient   : NA \nContingency Coeff.: 0.597 \nCramer's V        : 0.744 \n\n\nPractical implication for your clustering workflow:\nA Cramér’s V of 0.7443093 strongly suggests these two categorical variables carry overlapping information. If both are included in clustering, the algorithm may effectively double count the same underlying structure, increasing the weight of that dimension in cluster formation.\nCluster Quality: Silhouette Analysis\nSilhouette analysis measures how similar an object is to its own cluster compared to other clusters. The silhouette value ranges from -1 to 1, where a value close to 1 indicates that the object is well clustered, a value of 0 indicates that the object is on or very close to the decision boundary between two neighboring clusters, and negative values indicate that the object may have been assigned to the wrong cluster.\n\ndist_matrix &lt;- cluster_data_2025 %&gt;%\n  select(-cluster, -diabetes) %&gt;%\n  cluster::daisy(metric = \"gower\")\n\n\nsil &lt;- silhouette(kp_model$cluster, dist_matrix)\nmean(sil[, 3])\n\n[1] 0.2102046\n\n\n\nplot(sil, col = 1:optimal_k, \n     border = NA, \n     main = \"Silhouette Plot\")\n\n\n\n\n\n\n\nKey Clinical Insights\nThe k-prototypes clustering reveals clinically interpretable subgroups within the 2025 population, reflecting distinct metabolic profiles rather than arbitrary partitions.\nCluster 4 concentrates individuals with clearly elevated HbA1c levels (mean ≈ 8%), corresponding to the diagnosed diabetic population, although separation from neighbouring clusters is weaker than for some other groups.\nCluster 5 represents a pre-diabetic risk profile, characterised by younger individuals—predominantly women—who may benefit from early monitoring and preventive intervention.\nClusters 1–3 capture different non-diabetic phenotypes with broadly healthy metabolic profiles and varying demographic compositions.\nOverall, the clustering distinguishes diabetic from non-diabetic individuals in a meaningful way, as supported by external validation using diabetes status, while also highlighting substantial overlap consistent with diabetes risk existing along a continuum rather than as discrete categories.\nThis analysis reinforces that diabetes risk is not uniform across the population but varies systematically with age, sex, and BMI, supporting the use of stratified screening and targeted pre ,considering that this data is simulated and not real-world, the clinical interpretations should be viewed as illustrative rather than definitive.",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#bonus",
    "href": "02-exploring-diabetes-data.html#bonus",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Bonus",
    "text": "Bonus\nFrequency Table for BMI Categories\n\ncrosstable(df_diabetes, by = \"year\", \n           cols = c(\"sex\",\"diabetes_total\",\n                    \"bmi_cat\",\"country\",\"sdi\")) %&gt;%\n  as_flextable() \n\n\n\n\n\n\nlabel\nvariable\nyear\n\n\n2015\n2025\n\n\n\n\nsex\nmen\n125 (50.00%)\n125 (50.00%)\n\n\nwoman\n125 (50.00%)\n125 (50.00%)\n\n\ndiabetes_total\nno\n212 (53.00%)\n188 (47.00%)\n\n\nyes\n38 (38.00%)\n62 (62.00%)\n\n\nbmi_cat\nNormal weight\n95 (48.22%)\n102 (51.78%)\n\n\nObesity\n56 (54.90%)\n46 (45.10%)\n\n\nOverweight\n85 (52.15%)\n78 (47.85%)\n\n\nUnderweight\n14 (36.84%)\n24 (63.16%)\n\n\ncountry\nBrazil\n33 (33.00%)\n67 (67.00%)\n\n\nChina\n66 (56.90%)\n50 (43.10%)\n\n\nItaly\n34 (40.48%)\n50 (59.52%)\n\n\nSouth Africa\n67 (67.00%)\n33 (33.00%)\n\n\nUSA\n50 (50.00%)\n50 (50.00%)\n\n\nsdi\nHigh\n100 (50.00%)\n100 (50.00%)\n\n\nIntermediate\n100 (50.00%)\n100 (50.00%)\n\n\nLow\n50 (50.00%)\n50 (50.00%)\n\n\n\n\n\n\nBMI Categories by Year\nThe distribution of BMI categories by year can be examined using counts and proportions.\n\ndf_diabetes %&gt;%\n  count(year, bmi_cat) %&gt;%\n  group_by(year) %&gt;%\n  mutate(prop = n / sum(n))\n\n# A tibble: 8 × 4\n# Groups:   year [2]\n   year bmi_cat           n  prop\n  &lt;dbl&gt; &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1  2015 Normal weight    95 0.38 \n2  2015 Obesity          56 0.224\n3  2015 Overweight       85 0.34 \n4  2015 Underweight      14 0.056\n5  2025 Normal weight   102 0.408\n6  2025 Obesity          46 0.184\n7  2025 Overweight       78 0.312\n8  2025 Underweight      24 0.096\n\n\nVisualizing BMI Categories by Year\n\nggplot(data = df_diabetes, \n       aes(x = bmi_cat, fill = factor(year))) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"BMI categories by year\",\n       x = \"BMI category\",\n       y = \"Count\",\n       fill = \"Year\")\n\n\n\n\n\n\n\nProportional Distribution of BMI Categories by Year\n\nggplot(df_diabetes, \n       aes(x = bmi_cat, fill = factor(year))) +\n  geom_bar(position = \"fill\") +\n  scale_y_continuous(labels = scales::percent) +\n  labs(title = \"BMI categories by year (proportions)\",\n       x = \"BMI category\",\n       y = \"Proportion\",\n       fill = \"Year\")",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "02-exploring-diabetes-data.html#footnotes",
    "href": "02-exploring-diabetes-data.html#footnotes",
    "title": "From Basics to Advanced Health Analytics: Exploring Diabetes Data",
    "section": "Footnotes",
    "text": "Footnotes\n\nGlobal, regional, and national cascades of diabetes care, 2000–23: a systematic review and modelling analysis using findings from the Global Burden of Disease Study, Stafford, Lauryn K et al. The Lancet Diabetes & Endocrinology, Volume 13, Issue 11, 924 - 934 (https://doi.org/10.1016/S2213-8587(25)00217-7)↩︎\nBurden of 375 diseases and injuries, risk-attributable burden of 88 risk factors, and healthy life expectancy in 204 countries and territories, including 660 subnational locations, 1990–2023: a systematic analysis for the Global Burden of Disease Study 2023 Hay, Simon I et al. The Lancet, Volume 406, Issue 10513, 1873 - 1922 (https://doi.org/10.1016/S0140-6736(25)01637-X)↩︎",
    "crumbs": [
      "About Us",
      "3. Data Analytics",
      "3.1 Exploring Diabetes Data"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R Ladies Rome presents: Principles of Data Analysis in R",
    "section": "",
    "text": "Teaching R means learning how to think with data using R as a practical analytical tool.\nOur approach focuses on real workflows: importing data, cleaning and transforming it, exploring patterns, applying appropriate statistical methods, and communicating results clearly. The emphasis is not on memorising functions, but on developing sound analytical reasoning, reproducible practices, and confidence in interpreting outputs. R is used as a support for analysis, not as an end in itself.\nThis series of guides aims to provide a comprehensive introduction to the principles of data analysis using R. Each guide focuses on a specific aspect of data analysis, from data cleaning and manipulation to visualization and statistical modelling. The guides are designed for beginners and intermediate users who want to enhance their skills in R programming and data analysis.\n\n\n\n Back to top",
    "crumbs": [
      "About Us",
      "1. Welcome"
    ]
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2025 Principles-of-data-Analysis-in-R authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "01-getting-started.html",
    "href": "01-getting-started.html",
    "title": "Getting Started with R and RStudio",
    "section": "",
    "text": "Welcome to the “Getting Started with R and RStudio” guide! This guide is designed to help beginners set up their R programming environment and get familiar with the basics of R and RStudio.",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#overview",
    "href": "01-getting-started.html#overview",
    "title": "Getting Started with R and RStudio",
    "section": "",
    "text": "Welcome to the “Getting Started with R and RStudio” guide! This guide is designed to help beginners set up their R programming environment and get familiar with the basics of R and RStudio.",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#installing-r-and-rstudio",
    "href": "01-getting-started.html#installing-r-and-rstudio",
    "title": "Getting Started with R and RStudio",
    "section": "Installing R and RStudio",
    "text": "Installing R and RStudio\n\n\nInstall R:\n\nGo to the CRAN website and download the latest version of R for your operating system (Windows, macOS, or Linux).\nFollow the installation instructions provided on the website.\n\n\n\nInstall RStudio:\n\nVisit the RStudio website\n\nDownload the free version of RStudio Desktop and install it on your computer.\n\n\nLaunch RStudio: Open RStudio after installation. You should see the RStudio interface with multiple panes.",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#rstudio-interface-overview",
    "href": "01-getting-started.html#rstudio-interface-overview",
    "title": "Getting Started with R and RStudio",
    "section": "RStudio Interface Overview",
    "text": "RStudio Interface Overview\nThe RStudio interface consists of several key panes:\n\n\nSource Pane: This is where you can write and edit your R scripts and R Markdown documents.\n\nConsole Pane: This is where you can type and execute R commands directly.\n\nEnvironment/History Pane: This pane shows the variables and data frames in your current R session, as well as a history of commands you’ve executed.\n\nFiles/Plots/Packages/Help/Viewer Pane: This pane allows you to navigate files, view plots, manage packages, access help documentation, and view web content.",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#writing-your-first-r-script",
    "href": "01-getting-started.html#writing-your-first-r-script",
    "title": "Getting Started with R and RStudio",
    "section": "Writing Your First R Script",
    "text": "Writing Your First R Script\n\nIn the Source Pane, click on “File” &gt; “New File” &gt; “R Script” to create a new R script.\nType the following code into the script:\n\n\n2+2\n\n[1] 4\n\n\n\nTo run the code, highlight the line and click the “Run” button or press Ctrl + Enter (Windows) or Cmd + Enter (Mac). You should see the output 4 in the Console Pane.",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#basic-r-commands",
    "href": "01-getting-started.html#basic-r-commands",
    "title": "Getting Started with R and RStudio",
    "section": "Basic R Commands",
    "text": "Basic R Commands\nHere are some basic R commands to get you started:\n\nAssigning values to variables:\n\n\nx &lt;- 10\ny &lt;- 5\n\n\nPerforming arithmetic operations:\n\n\nsum &lt;- x + y\nproduct &lt;- x * y\n\n\nCreating a vector:\n\n\nmy_vector &lt;- c(1, 2, 3, 4, 5)\n\n\nViewing the contents of a variable:\n\n\nprint(my_vector)\n\n[1] 1 2 3 4 5",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#installing-and-loading-packages",
    "href": "01-getting-started.html#installing-and-loading-packages",
    "title": "Getting Started with R and RStudio",
    "section": "Installing and Loading Packages",
    "text": "Installing and Loading Packages\nR has a vast ecosystem of packages that extend its functionality. To install and load packages, follow these steps:\n\nTo install a package, use the install.packages() function. For example,\n\n\ninstall.packages(\"ggplot2\")\n\n\nTo load a package into your R session, use the library() function:\n\n\nlibrary(ggplot2)",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "01-getting-started.html#next-steps",
    "href": "01-getting-started.html#next-steps",
    "title": "Getting Started with R and RStudio",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you have set up R and RStudio and learned some basic commands, you can explore more advanced topics in R programming and data analysis. Check out the next guide in this series, From Basics to Advanced Health Analytics: Exploring Diabetes Data, to dive deeper into data analysis using R.",
    "crumbs": [
      "About Us",
      "2. Getting Started"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "We teach R as a tool for data analysis, not as an abstract programming language. Our sessions focus on clear workflows, reproducible analysis, and interpretation of results using real-world examples.\nThe project is curated by Rafaela Ribeiro Lucas, Federica Gazzelloni, and Lucy Michaels. Together, we combine experience in statistics, data science, and applied research to deliver practical, accessible, and methodologically sound R training."
  },
  {
    "objectID": "about.html#bios-of-the-instructors",
    "href": "about.html#bios-of-the-instructors",
    "title": "About Us",
    "section": "Bios of the Instructors",
    "text": "Bios of the Instructors\n\n\nRafaela Ribeiro Lucas Lucas is a Nutritionist with academic training from the Federal University of Pelotas (UFPel) and a postgraduate degree in Eating Behavior from Institute of Research, Teaching, and Health Management (iPGS). And a Master’s degree in Cardiology and Cardiovascular Sciences at the Federal University of Rio Grande do Sul (UFRGS) Her work is based on methodological and statistical applications in the investigation of cardiovascular risk factors and disease. She is passionate about Population Epidemiology, Epidemiological Surveillance, and analytical methods for longitudinal studies and complex survey designs.\n\n\n\n\n\n\nFederica Gazzelloni is an independent researcher, statistician, and instructor specialising in data visualisation, statistical modelling, and data-driven storytelling. She leads R-Ladies Rome and co-organises the Rome R Users Group, promoting inclusive, hands-on learning for the local R and data-science community. Federica collaborates with international organisations, contributes to open-source projects, and develops educational resources spanning R, spatial analysis, and health metrics. She is passionate about building welcoming spaces where people can learn, experiment, and meet others who share a curiosity for data.\n\n\n\n\n\n\nLucy Michaels is a Data Scientist with academic training from Unitelma Sapienza, where she completed a Master’s degree in Analysis and Modeling of Data and Processes. She specialises in applied statistics, machine learning, and analytical modelling for complex real-world problems. Her recent work focuses on methodological and statistical approaches for understanding pedestrian-accident risk in urban environments, integrating multi-source datasets on visibility, weather, twilight phases, road conditions, and vehicle involvement. She is passionate about urban mobility analytics, public-health informatics, and data-driven decision-making for safer cities. Her interests include geospatial analysis, mixed-data clustering and designing reproducible analytical pipelines.\n\n\n\n\nFollow Us on Meetup: RLadiesRome"
  }
]